{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook includes the code for scraping the Twitter API for terms related to both diabetes and general health issues.  Authentication data has been deleted before publishing publicly (THIS WILL BE DONE AFTER SUBMISSION / APPROVAL).  The list of search terms is included in the cell above the function to retrieve tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Tweepy API\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import time\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import API\n",
    "from tweepy.streaming import StreamListener \n",
    "from tweepy import Stream \n",
    "import tweepy\n",
    "# scrape tweets\n",
    "from twitterscraper import query_tweets\n",
    "\n",
    "\n",
    "# For dataframes\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "import json\n",
    "from flatten_json import flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweepy.error.TweepError"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweepy.TweepError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inherits from the StreamListener class &\n",
    "# opens new timestamped file to store tweets\n",
    "class SListener(StreamListener):\n",
    "    def __init__(self, api = None):\n",
    "        self.output = open('tweets_%s.json' %\n",
    "                          time.strftime('%Y%m%d-%H%M%S'), 'w')\n",
    "        self.api = api or API()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This accesses authentication but does not save in pickle file\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "Twitter={}\n",
    "Twitter['Consumer Key'] = 'REDACTED' Twitter['Consumer Secret'] = 'REDACTED'\n",
    "Twitter['Access Token'] = 'REDACTED'\n",
    "Twitter['Access Token Secret'] = 'REDACTED'\n",
    "with open('secret_twitter_credentials.pkl','wb') as f:\n",
    "    pickle.dump(Twitter, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeSantisA\n"
     ]
    }
   ],
   "source": [
    "from tweepy import OAuthHandler\n",
    "from tweepy import API\n",
    "\n",
    "auth = OAuthHandler(Twitter['Consumer Key'], Twitter['Consumer Secret'])\n",
    "auth.set_access_token(Twitter['Access Token'], Twitter['Access Token Secret'])\n",
    "\n",
    "api = API(auth)\n",
    "\n",
    "# If the authentication was successful, you should\n",
    "# see the name of the account print out\n",
    "print(api.me().name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "# api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tweepy.api.API at 0x11fee9ba8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#LIST OF TERMS INCLUDED IN QUERIES \n",
    "\n",
    "        Diabetes / diabetic\n",
    "\t \tDiagnosis / diagnosed\n",
    "\t \t\n",
    "\t\t\"I was diagnosed with t2 / type 2 diabetes\"\n",
    "\t\t\"I was diagnosed with diabetes\"  \n",
    "\t\t\"I have diabetes\"\n",
    "\t\t\"I have type 2 / t2 diabetes\"\n",
    "\t\t\"I am /I'm diabetic\n",
    "\t\tI am a diabetic\n",
    "\n",
    "Additional words searched (determined from Reddit NLP):\n",
    "\t\n",
    "\t\t\t\n",
    "\t\to\tChest (2018)\n",
    "\t\to\tDoctor (2018)\n",
    "\t\to\tHeart (2018)\n",
    "\t\to\tSymptoms (2018)\n",
    "\t\to\tPain (2018)\n",
    "\t\to\tSkin (2018) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE QUERY FUNCTION TO CREATE THE DICTIONARY \n",
    "\n",
    "def get_query(query, begin, end):\n",
    "\n",
    "    tweety=[] \n",
    "    try:\n",
    "        for tweet in query_tweets(query, limit=1, begindate=begin, enddate=end):\n",
    "            tweets_dict = {}\n",
    "            # Append info to tweets_dict\n",
    "            tweets_dict['timestamp']=tweet.timestamp\n",
    "            tweets_dict['id']= tweet.id\n",
    "            tweets_dict['text']=tweet.text\n",
    "            tweets_dict['user']=tweet.user\n",
    "            tweets_dict['likes']=tweet.likes\n",
    "            tweets_dict['replies']=tweet.replies\n",
    "            tweets_dict['retweets']=tweet.retweets\n",
    "            tweets_dict['user_location']=api.get_user(tweet.user).location \n",
    "            tweety.append(tweets_dict) \n",
    "        time.sleep(1)\n",
    "#CHECK FOR TIMING ERRORS -WAIT\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "        time.sleep(600)\n",
    "        \n",
    "    return tweety    \n",
    "# \"lang:en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ENTER QUERY TERM AND DATES TO SEARCH - REPEAT MONTHLY\n",
    "\n",
    "query = (\"symptoms\")\n",
    "\n",
    "begin = dt.date(2018,1,1)\n",
    "end = dt.date(2018,1,31)\n",
    "\n",
    "tweety = []\n",
    "\n",
    "for i in range(12):\n",
    "    tweety.extend(get_query(query, begin, end))\n",
    "    begin = end + timedelta(1)\n",
    "    \n",
    "    x = begin\n",
    "    d = 1\n",
    "    while x.month == begin.month:\n",
    "        x = begin + timedelta(d)\n",
    "        d+=1\n",
    "    end = x - timedelta(1)\n",
    "    print(begin, end)\n",
    "    \n",
    "\n",
    "tweets = pd.DataFrame(tweety)\n",
    "\n",
    "tweets.set_index('timestamp', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.DataFrame(tweety)\n",
    "tweets.set_index('timestamp', inplace=True)\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check number of total vs unique observations\n",
    "print(f\"Total: {tweets.shape[0]}\")\n",
    "print(f\"Unique: {tweets['id'].nunique()}\")\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "tweets.drop_duplicates(inplace=True)\n",
    "print(f\"Total: {tweets.shape[0]}\")\n",
    "print(f\"Unique: {tweets['id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append results to .csv file\n",
    "with open('./2018symptoms.csv', 'a') as f:\n",
    "    tweets.to_csv(f, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: queries: ['skin since:2018-01-01 until:2018-01-02', 'skin since:2018-01-02 until:2018-01-04', 'skin since:2018-01-04 until:2018-01-05', 'skin since:2018-01-05 until:2018-01-07', 'skin since:2018-01-07 until:2018-01-08', 'skin since:2018-01-08 until:2018-01-10', 'skin since:2018-01-10 until:2018-01-11', 'skin since:2018-01-11 until:2018-01-13', 'skin since:2018-01-13 until:2018-01-14', 'skin since:2018-01-14 until:2018-01-16', 'skin since:2018-01-16 until:2018-01-17', 'skin since:2018-01-17 until:2018-01-19', 'skin since:2018-01-19 until:2018-01-20', 'skin since:2018-01-20 until:2018-01-22', 'skin since:2018-01-22 until:2018-01-23', 'skin since:2018-01-23 until:2018-01-25', 'skin since:2018-01-25 until:2018-01-26', 'skin since:2018-01-26 until:2018-01-28', 'skin since:2018-01-28 until:2018-01-29', 'skin since:2018-01-29 until:2018-01-31']\n",
      "INFO: Querying skin since:2018-01-02 until:2018-01-04\n",
      "INFO: Querying skin since:2018-01-01 until:2018-01-02\n",
      "INFO: Querying skin since:2018-01-07 until:2018-01-08\n",
      "INFO: Querying skin since:2018-01-05 until:2018-01-07\n",
      "INFO: Querying skin since:2018-01-04 until:2018-01-05\n",
      "INFO: Querying skin since:2018-01-08 until:2018-01-10\n",
      "INFO: Querying skin since:2018-01-10 until:2018-01-11\n",
      "INFO: Querying skin since:2018-01-11 until:2018-01-13\n",
      "INFO: Querying skin since:2018-01-13 until:2018-01-14\n",
      "INFO: Querying skin since:2018-01-14 until:2018-01-16\n",
      "INFO: Querying skin since:2018-01-16 until:2018-01-17\n",
      "INFO: Querying skin since:2018-01-17 until:2018-01-19\n",
      "INFO: Querying skin since:2018-01-19 until:2018-01-20\n",
      "INFO: Querying skin since:2018-01-20 until:2018-01-22\n",
      "INFO: Querying skin since:2018-01-22 until:2018-01-23\n",
      "INFO: Querying skin since:2018-01-23 until:2018-01-25\n",
      "INFO: Querying skin since:2018-01-25 until:2018-01-26\n",
      "INFO: Querying skin since:2018-01-26 until:2018-01-28\n",
      "INFO: Querying skin since:2018-01-28 until:2018-01-29\n",
      "INFO: Querying skin since:2018-01-29 until:2018-01-31\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-01-28%20until%3A2018-01-29.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-01-05%20until%3A2018-01-07.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-01-16%20until%3A2018-01-17.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-01-01%20until%3A2018-01-02.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-01-23%20until%3A2018-01-25.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-01-20%20until%3A2018-01-22.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-01-26%20until%3A2018-01-28.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-01-19%20until%3A2018-01-20.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-01-17%20until%3A2018-01-19.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-01-11%20until%3A2018-01-13.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-01-14%20until%3A2018-01-16.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-01-08%20until%3A2018-01-10.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-01-22%20until%3A2018-01-23.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-01-02%20until%3A2018-01-04.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-01-04%20until%3A2018-01-05.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-01-10%20until%3A2018-01-11.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-01-25%20until%3A2018-01-26.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-01-07%20until%3A2018-01-08.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-01-13%20until%3A2018-01-14.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-01-29%20until%3A2018-01-31.\n",
      "INFO: Got 0 tweets (0 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-02-01 2018-02-28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: queries: ['skin since:2018-02-01 until:2018-02-02', 'skin since:2018-02-02 until:2018-02-03', 'skin since:2018-02-03 until:2018-02-05', 'skin since:2018-02-05 until:2018-02-06', 'skin since:2018-02-06 until:2018-02-07', 'skin since:2018-02-07 until:2018-02-09', 'skin since:2018-02-09 until:2018-02-10', 'skin since:2018-02-10 until:2018-02-11', 'skin since:2018-02-11 until:2018-02-13', 'skin since:2018-02-13 until:2018-02-14', 'skin since:2018-02-14 until:2018-02-15', 'skin since:2018-02-15 until:2018-02-17', 'skin since:2018-02-17 until:2018-02-18', 'skin since:2018-02-18 until:2018-02-19', 'skin since:2018-02-19 until:2018-02-21', 'skin since:2018-02-21 until:2018-02-22', 'skin since:2018-02-22 until:2018-02-23', 'skin since:2018-02-23 until:2018-02-25', 'skin since:2018-02-25 until:2018-02-26', 'skin since:2018-02-26 until:2018-02-28']\n",
      "INFO: Querying skin since:2018-02-02 until:2018-02-03\n",
      "INFO: Querying skin since:2018-02-03 until:2018-02-05\n",
      "INFO: Querying skin since:2018-02-01 until:2018-02-02\n",
      "INFO: Querying skin since:2018-02-07 until:2018-02-09\n",
      "INFO: Querying skin since:2018-02-05 until:2018-02-06\n",
      "INFO: Querying skin since:2018-02-11 until:2018-02-13\n",
      "INFO: Querying skin since:2018-02-06 until:2018-02-07\n",
      "INFO: Querying skin since:2018-02-15 until:2018-02-17\n",
      "INFO: Querying skin since:2018-02-10 until:2018-02-11\n",
      "INFO: Querying skin since:2018-02-14 until:2018-02-15\n",
      "INFO: Querying skin since:2018-02-17 until:2018-02-18\n",
      "INFO: Querying skin since:2018-02-13 until:2018-02-14\n",
      "INFO: Querying skin since:2018-02-09 until:2018-02-10\n",
      "INFO: Querying skin since:2018-02-18 until:2018-02-19\n",
      "INFO: Querying skin since:2018-02-19 until:2018-02-21\n",
      "INFO: Querying skin since:2018-02-21 until:2018-02-22\n",
      "INFO: Querying skin since:2018-02-22 until:2018-02-23\n",
      "INFO: Querying skin since:2018-02-23 until:2018-02-25\n",
      "INFO: Querying skin since:2018-02-25 until:2018-02-26\n",
      "INFO: Querying skin since:2018-02-26 until:2018-02-28\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-02-17%20until%3A2018-02-18.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-02-18%20until%3A2018-02-19.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-02-22%20until%3A2018-02-23.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-02-19%20until%3A2018-02-21.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-02-05%20until%3A2018-02-06.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-02-02%20until%3A2018-02-03.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-02-03%20until%3A2018-02-05.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-02-25%20until%3A2018-02-26.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-02-07%20until%3A2018-02-09.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-02-23%20until%3A2018-02-25.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-02-14%20until%3A2018-02-15.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-02-13%20until%3A2018-02-14.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-02-26%20until%3A2018-02-28.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-02-10%20until%3A2018-02-11.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-02-01%20until%3A2018-02-02.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-02-11%20until%3A2018-02-13.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-02-06%20until%3A2018-02-07.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-02-21%20until%3A2018-02-22.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-02-09%20until%3A2018-02-10.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-02-15%20until%3A2018-02-17.\n",
      "INFO: Got 0 tweets (0 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-01 2018-03-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: queries: ['skin since:2018-03-01 until:2018-03-02', 'skin since:2018-03-02 until:2018-03-04', 'skin since:2018-03-04 until:2018-03-05', 'skin since:2018-03-05 until:2018-03-07', 'skin since:2018-03-07 until:2018-03-08', 'skin since:2018-03-08 until:2018-03-10', 'skin since:2018-03-10 until:2018-03-11', 'skin since:2018-03-11 until:2018-03-13', 'skin since:2018-03-13 until:2018-03-14', 'skin since:2018-03-14 until:2018-03-16', 'skin since:2018-03-16 until:2018-03-17', 'skin since:2018-03-17 until:2018-03-19', 'skin since:2018-03-19 until:2018-03-20', 'skin since:2018-03-20 until:2018-03-22', 'skin since:2018-03-22 until:2018-03-23', 'skin since:2018-03-23 until:2018-03-25', 'skin since:2018-03-25 until:2018-03-26', 'skin since:2018-03-26 until:2018-03-28', 'skin since:2018-03-28 until:2018-03-29', 'skin since:2018-03-29 until:2018-03-31']\n",
      "INFO: Querying skin since:2018-03-01 until:2018-03-02\n",
      "INFO: Querying skin since:2018-03-02 until:2018-03-04\n",
      "INFO: Querying skin since:2018-03-04 until:2018-03-05\n",
      "INFO: Querying skin since:2018-03-05 until:2018-03-07\n",
      "INFO: Querying skin since:2018-03-13 until:2018-03-14\n",
      "INFO: Querying skin since:2018-03-14 until:2018-03-16\n",
      "INFO: Querying skin since:2018-03-16 until:2018-03-17\n",
      "INFO: Querying skin since:2018-03-17 until:2018-03-19\n",
      "INFO: Querying skin since:2018-03-07 until:2018-03-08\n",
      "INFO: Querying skin since:2018-03-10 until:2018-03-11\n",
      "INFO: Querying skin since:2018-03-11 until:2018-03-13\n",
      "INFO: Querying skin since:2018-03-08 until:2018-03-10\n",
      "INFO: Querying skin since:2018-03-20 until:2018-03-22\n",
      "INFO: Querying skin since:2018-03-22 until:2018-03-23\n",
      "INFO: Querying skin since:2018-03-23 until:2018-03-25\n",
      "INFO: Querying skin since:2018-03-26 until:2018-03-28\n",
      "INFO: Querying skin since:2018-03-25 until:2018-03-26\n",
      "INFO: Querying skin since:2018-03-29 until:2018-03-31\n",
      "INFO: Querying skin since:2018-03-19 until:2018-03-20\n",
      "INFO: Querying skin since:2018-03-28 until:2018-03-29\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-03-02%20until%3A2018-03-04.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-03-11%20until%3A2018-03-13.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-03-08%20until%3A2018-03-10.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-03-04%20until%3A2018-03-05.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-03-01%20until%3A2018-03-02.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-03-05%20until%3A2018-03-07.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-03-14%20until%3A2018-03-16.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-03-16%20until%3A2018-03-17.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-03-13%20until%3A2018-03-14.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-03-22%20until%3A2018-03-23.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-03-07%20until%3A2018-03-08.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-03-28%20until%3A2018-03-29.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-03-10%20until%3A2018-03-11.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-03-20%20until%3A2018-03-22.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-03-29%20until%3A2018-03-31.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-03-17%20until%3A2018-03-19.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-03-26%20until%3A2018-03-28.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-03-25%20until%3A2018-03-26.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-03-23%20until%3A2018-03-25.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-03-19%20until%3A2018-03-20.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-04-01 2018-04-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: queries: ['skin since:2018-04-01 until:2018-04-02', 'skin since:2018-04-02 until:2018-04-03', 'skin since:2018-04-03 until:2018-04-05', 'skin since:2018-04-05 until:2018-04-06', 'skin since:2018-04-06 until:2018-04-08', 'skin since:2018-04-08 until:2018-04-09', 'skin since:2018-04-09 until:2018-04-11', 'skin since:2018-04-11 until:2018-04-12', 'skin since:2018-04-12 until:2018-04-14', 'skin since:2018-04-14 until:2018-04-15', 'skin since:2018-04-15 until:2018-04-16', 'skin since:2018-04-16 until:2018-04-18', 'skin since:2018-04-18 until:2018-04-19', 'skin since:2018-04-19 until:2018-04-21', 'skin since:2018-04-21 until:2018-04-22', 'skin since:2018-04-22 until:2018-04-24', 'skin since:2018-04-24 until:2018-04-25', 'skin since:2018-04-25 until:2018-04-27', 'skin since:2018-04-27 until:2018-04-28', 'skin since:2018-04-28 until:2018-04-30']\n",
      "INFO: Querying skin since:2018-04-02 until:2018-04-03\n",
      "INFO: Querying skin since:2018-04-05 until:2018-04-06\n",
      "INFO: Querying skin since:2018-04-01 until:2018-04-02\n",
      "INFO: Querying skin since:2018-04-03 until:2018-04-05\n",
      "INFO: Querying skin since:2018-04-06 until:2018-04-08\n",
      "INFO: Querying skin since:2018-04-08 until:2018-04-09\n",
      "INFO: Querying skin since:2018-04-11 until:2018-04-12\n",
      "INFO: Querying skin since:2018-04-09 until:2018-04-11\n",
      "INFO: Querying skin since:2018-04-12 until:2018-04-14\n",
      "INFO: Querying skin since:2018-04-15 until:2018-04-16\n",
      "INFO: Querying skin since:2018-04-14 until:2018-04-15\n",
      "INFO: Querying skin since:2018-04-16 until:2018-04-18\n",
      "INFO: Querying skin since:2018-04-18 until:2018-04-19\n",
      "INFO: Querying skin since:2018-04-21 until:2018-04-22\n",
      "INFO: Querying skin since:2018-04-19 until:2018-04-21\n",
      "INFO: Querying skin since:2018-04-24 until:2018-04-25\n",
      "INFO: Querying skin since:2018-04-22 until:2018-04-24\n",
      "INFO: Querying skin since:2018-04-28 until:2018-04-30\n",
      "INFO: Querying skin since:2018-04-25 until:2018-04-27\n",
      "INFO: Querying skin since:2018-04-27 until:2018-04-28\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-04-16%20until%3A2018-04-18.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-04-05%20until%3A2018-04-06.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-04-12%20until%3A2018-04-14.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-04-08%20until%3A2018-04-09.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-04-25%20until%3A2018-04-27.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-04-19%20until%3A2018-04-21.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-04-18%20until%3A2018-04-19.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-04-21%20until%3A2018-04-22.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-04-28%20until%3A2018-04-30.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-04-09%20until%3A2018-04-11.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-04-22%20until%3A2018-04-24.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-04-11%20until%3A2018-04-12.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-04-02%20until%3A2018-04-03.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-04-01%20until%3A2018-04-02.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-04-03%20until%3A2018-04-05.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-04-27%20until%3A2018-04-28.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-04-14%20until%3A2018-04-15.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-04-24%20until%3A2018-04-25.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-04-15%20until%3A2018-04-16.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-04-06%20until%3A2018-04-08.\n",
      "INFO: Got 0 tweets (0 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-01 2018-05-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: queries: ['skin since:2018-05-01 until:2018-05-02', 'skin since:2018-05-02 until:2018-05-04', 'skin since:2018-05-04 until:2018-05-05', 'skin since:2018-05-05 until:2018-05-07', 'skin since:2018-05-07 until:2018-05-08', 'skin since:2018-05-08 until:2018-05-10', 'skin since:2018-05-10 until:2018-05-11', 'skin since:2018-05-11 until:2018-05-13', 'skin since:2018-05-13 until:2018-05-14', 'skin since:2018-05-14 until:2018-05-16', 'skin since:2018-05-16 until:2018-05-17', 'skin since:2018-05-17 until:2018-05-19', 'skin since:2018-05-19 until:2018-05-20', 'skin since:2018-05-20 until:2018-05-22', 'skin since:2018-05-22 until:2018-05-23', 'skin since:2018-05-23 until:2018-05-25', 'skin since:2018-05-25 until:2018-05-26', 'skin since:2018-05-26 until:2018-05-28', 'skin since:2018-05-28 until:2018-05-29', 'skin since:2018-05-29 until:2018-05-31']\n",
      "INFO: Querying skin since:2018-05-02 until:2018-05-04\n",
      "INFO: Querying skin since:2018-05-04 until:2018-05-05\n",
      "INFO: Querying skin since:2018-05-07 until:2018-05-08\n",
      "INFO: Querying skin since:2018-05-05 until:2018-05-07\n",
      "INFO: Querying skin since:2018-05-08 until:2018-05-10\n",
      "INFO: Querying skin since:2018-05-01 until:2018-05-02\n",
      "INFO: Querying skin since:2018-05-10 until:2018-05-11\n",
      "INFO: Querying skin since:2018-05-11 until:2018-05-13\n",
      "INFO: Querying skin since:2018-05-14 until:2018-05-16\n",
      "INFO: Querying skin since:2018-05-13 until:2018-05-14\n",
      "INFO: Querying skin since:2018-05-17 until:2018-05-19\n",
      "INFO: Querying skin since:2018-05-16 until:2018-05-17\n",
      "INFO: Querying skin since:2018-05-19 until:2018-05-20\n",
      "INFO: Querying skin since:2018-05-20 until:2018-05-22\n",
      "INFO: Querying skin since:2018-05-22 until:2018-05-23\n",
      "INFO: Querying skin since:2018-05-23 until:2018-05-25\n",
      "INFO: Querying skin since:2018-05-25 until:2018-05-26\n",
      "INFO: Querying skin since:2018-05-28 until:2018-05-29\n",
      "INFO: Querying skin since:2018-05-26 until:2018-05-28\n",
      "INFO: Querying skin since:2018-05-29 until:2018-05-31\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-05-29%20until%3A2018-05-31.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-05-10%20until%3A2018-05-11.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-05-19%20until%3A2018-05-20.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-05-25%20until%3A2018-05-26.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-05-20%20until%3A2018-05-22.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-05-01%20until%3A2018-05-02.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-05-07%20until%3A2018-05-08.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-05-04%20until%3A2018-05-05.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-05-17%20until%3A2018-05-19.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-05-13%20until%3A2018-05-14.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-05-05%20until%3A2018-05-07.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-05-28%20until%3A2018-05-29.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-05-02%20until%3A2018-05-04.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-05-23%20until%3A2018-05-25.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-05-11%20until%3A2018-05-13.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-05-22%20until%3A2018-05-23.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-05-16%20until%3A2018-05-17.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-05-26%20until%3A2018-05-28.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-05-08%20until%3A2018-05-10.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-05-14%20until%3A2018-05-16.\n",
      "INFO: Got 0 tweets (0 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-01 2018-06-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: queries: ['skin since:2018-06-01 until:2018-06-02', 'skin since:2018-06-02 until:2018-06-03', 'skin since:2018-06-03 until:2018-06-05', 'skin since:2018-06-05 until:2018-06-06', 'skin since:2018-06-06 until:2018-06-08', 'skin since:2018-06-08 until:2018-06-09', 'skin since:2018-06-09 until:2018-06-11', 'skin since:2018-06-11 until:2018-06-12', 'skin since:2018-06-12 until:2018-06-14', 'skin since:2018-06-14 until:2018-06-15', 'skin since:2018-06-15 until:2018-06-16', 'skin since:2018-06-16 until:2018-06-18', 'skin since:2018-06-18 until:2018-06-19', 'skin since:2018-06-19 until:2018-06-21', 'skin since:2018-06-21 until:2018-06-22', 'skin since:2018-06-22 until:2018-06-24', 'skin since:2018-06-24 until:2018-06-25', 'skin since:2018-06-25 until:2018-06-27', 'skin since:2018-06-27 until:2018-06-28', 'skin since:2018-06-28 until:2018-06-30']\n",
      "INFO: Querying skin since:2018-06-02 until:2018-06-03\n",
      "INFO: Querying skin since:2018-06-05 until:2018-06-06\n",
      "INFO: Querying skin since:2018-06-01 until:2018-06-02\n",
      "INFO: Querying skin since:2018-06-03 until:2018-06-05\n",
      "INFO: Querying skin since:2018-06-06 until:2018-06-08\n",
      "INFO: Querying skin since:2018-06-08 until:2018-06-09\n",
      "INFO: Querying skin since:2018-06-09 until:2018-06-11\n",
      "INFO: Querying skin since:2018-06-12 until:2018-06-14\n",
      "INFO: Querying skin since:2018-06-14 until:2018-06-15\n",
      "INFO: Querying skin since:2018-06-15 until:2018-06-16\n",
      "INFO: Querying skin since:2018-06-11 until:2018-06-12\n",
      "INFO: Querying skin since:2018-06-16 until:2018-06-18\n",
      "INFO: Querying skin since:2018-06-22 until:2018-06-24\n",
      "INFO: Querying skin since:2018-06-19 until:2018-06-21\n",
      "INFO: Querying skin since:2018-06-18 until:2018-06-19\n",
      "INFO: Querying skin since:2018-06-24 until:2018-06-25\n",
      "INFO: Querying skin since:2018-06-21 until:2018-06-22\n",
      "INFO: Querying skin since:2018-06-27 until:2018-06-28\n",
      "INFO: Querying skin since:2018-06-25 until:2018-06-27\n",
      "INFO: Querying skin since:2018-06-28 until:2018-06-30\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-06-01%20until%3A2018-06-02.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-06-14%20until%3A2018-06-15.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-06-09%20until%3A2018-06-11.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-06-12%20until%3A2018-06-14.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-06-16%20until%3A2018-06-18.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-06-27%20until%3A2018-06-28.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-06-02%20until%3A2018-06-03.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-06-19%20until%3A2018-06-21.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-06-05%20until%3A2018-06-06.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-06-15%20until%3A2018-06-16.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-06-28%20until%3A2018-06-30.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-06-25%20until%3A2018-06-27.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-06-11%20until%3A2018-06-12.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-06-24%20until%3A2018-06-25.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-06-03%20until%3A2018-06-05.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-06-21%20until%3A2018-06-22.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-06-08%20until%3A2018-06-09.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-06-06%20until%3A2018-06-08.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-06-22%20until%3A2018-06-24.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-06-18%20until%3A2018-06-19.\n",
      "INFO: Got 0 tweets (0 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-07-01 2018-07-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: queries: ['skin since:2018-07-01 until:2018-07-02', 'skin since:2018-07-02 until:2018-07-04', 'skin since:2018-07-04 until:2018-07-05', 'skin since:2018-07-05 until:2018-07-07', 'skin since:2018-07-07 until:2018-07-08', 'skin since:2018-07-08 until:2018-07-10', 'skin since:2018-07-10 until:2018-07-11', 'skin since:2018-07-11 until:2018-07-13', 'skin since:2018-07-13 until:2018-07-14', 'skin since:2018-07-14 until:2018-07-16', 'skin since:2018-07-16 until:2018-07-17', 'skin since:2018-07-17 until:2018-07-19', 'skin since:2018-07-19 until:2018-07-20', 'skin since:2018-07-20 until:2018-07-22', 'skin since:2018-07-22 until:2018-07-23', 'skin since:2018-07-23 until:2018-07-25', 'skin since:2018-07-25 until:2018-07-26', 'skin since:2018-07-26 until:2018-07-28', 'skin since:2018-07-28 until:2018-07-29', 'skin since:2018-07-29 until:2018-07-31']\n",
      "INFO: Querying skin since:2018-07-01 until:2018-07-02\n",
      "INFO: Querying skin since:2018-07-04 until:2018-07-05\n",
      "INFO: Querying skin since:2018-07-05 until:2018-07-07\n",
      "INFO: Querying skin since:2018-07-02 until:2018-07-04\n",
      "INFO: Querying skin since:2018-07-07 until:2018-07-08\n",
      "INFO: Querying skin since:2018-07-08 until:2018-07-10\n",
      "INFO: Querying skin since:2018-07-11 until:2018-07-13\n",
      "INFO: Querying skin since:2018-07-10 until:2018-07-11\n",
      "INFO: Querying skin since:2018-07-14 until:2018-07-16\n",
      "INFO: Querying skin since:2018-07-13 until:2018-07-14\n",
      "INFO: Querying skin since:2018-07-17 until:2018-07-19\n",
      "INFO: Querying skin since:2018-07-16 until:2018-07-17\n",
      "INFO: Querying skin since:2018-07-19 until:2018-07-20\n",
      "INFO: Querying skin since:2018-07-25 until:2018-07-26\n",
      "INFO: Querying skin since:2018-07-22 until:2018-07-23\n",
      "INFO: Querying skin since:2018-07-28 until:2018-07-29\n",
      "INFO: Querying skin since:2018-07-23 until:2018-07-25\n",
      "INFO: Querying skin since:2018-07-26 until:2018-07-28\n",
      "INFO: Querying skin since:2018-07-20 until:2018-07-22\n",
      "INFO: Querying skin since:2018-07-29 until:2018-07-31\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-07-11%20until%3A2018-07-13.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-07-07%20until%3A2018-07-08.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-07-05%20until%3A2018-07-07.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-07-13%20until%3A2018-07-14.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-07-08%20until%3A2018-07-10.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-07-04%20until%3A2018-07-05.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-07-02%20until%3A2018-07-04.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-07-22%20until%3A2018-07-23.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-07-19%20until%3A2018-07-20.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-07-23%20until%3A2018-07-25.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-07-26%20until%3A2018-07-28.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-07-17%20until%3A2018-07-19.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-07-14%20until%3A2018-07-16.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-07-20%20until%3A2018-07-22.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-07-28%20until%3A2018-07-29.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-07-10%20until%3A2018-07-11.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-07-25%20until%3A2018-07-26.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-07-29%20until%3A2018-07-31.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-07-01%20until%3A2018-07-02.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-07-16%20until%3A2018-07-17.\n",
      "INFO: Got 0 tweets (0 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-01 2018-08-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: queries: ['skin since:2018-08-01 until:2018-08-02', 'skin since:2018-08-02 until:2018-08-04', 'skin since:2018-08-04 until:2018-08-05', 'skin since:2018-08-05 until:2018-08-07', 'skin since:2018-08-07 until:2018-08-08', 'skin since:2018-08-08 until:2018-08-10', 'skin since:2018-08-10 until:2018-08-11', 'skin since:2018-08-11 until:2018-08-13', 'skin since:2018-08-13 until:2018-08-14', 'skin since:2018-08-14 until:2018-08-16', 'skin since:2018-08-16 until:2018-08-17', 'skin since:2018-08-17 until:2018-08-19', 'skin since:2018-08-19 until:2018-08-20', 'skin since:2018-08-20 until:2018-08-22', 'skin since:2018-08-22 until:2018-08-23', 'skin since:2018-08-23 until:2018-08-25', 'skin since:2018-08-25 until:2018-08-26', 'skin since:2018-08-26 until:2018-08-28', 'skin since:2018-08-28 until:2018-08-29', 'skin since:2018-08-29 until:2018-08-31']\n",
      "INFO: Querying skin since:2018-08-02 until:2018-08-04\n",
      "INFO: Querying skin since:2018-08-04 until:2018-08-05\n",
      "INFO: Querying skin since:2018-08-13 until:2018-08-14\n",
      "INFO: Querying skin since:2018-08-10 until:2018-08-11\n",
      "INFO: Querying skin since:2018-08-01 until:2018-08-02\n",
      "INFO: Querying skin since:2018-08-11 until:2018-08-13\n",
      "INFO: Querying skin since:2018-08-14 until:2018-08-16\n",
      "INFO: Querying skin since:2018-08-05 until:2018-08-07\n",
      "INFO: Querying skin since:2018-08-07 until:2018-08-08\n",
      "INFO: Querying skin since:2018-08-08 until:2018-08-10\n",
      "INFO: Querying skin since:2018-08-16 until:2018-08-17\n",
      "INFO: Querying skin since:2018-08-20 until:2018-08-22\n",
      "INFO: Querying skin since:2018-08-22 until:2018-08-23\n",
      "INFO: Querying skin since:2018-08-19 until:2018-08-20\n",
      "INFO: Querying skin since:2018-08-23 until:2018-08-25\n",
      "INFO: Querying skin since:2018-08-17 until:2018-08-19\n",
      "INFO: Querying skin since:2018-08-25 until:2018-08-26\n",
      "INFO: Querying skin since:2018-08-26 until:2018-08-28\n",
      "INFO: Querying skin since:2018-08-28 until:2018-08-29\n",
      "INFO: Querying skin since:2018-08-29 until:2018-08-31\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-08-05%20until%3A2018-08-07.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-08-01%20until%3A2018-08-02.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-08-04%20until%3A2018-08-05.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-08-02%20until%3A2018-08-04.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-08-08%20until%3A2018-08-10.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-08-14%20until%3A2018-08-16.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-08-23%20until%3A2018-08-25.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-08-25%20until%3A2018-08-26.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-08-13%20until%3A2018-08-14.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-08-11%20until%3A2018-08-13.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-08-28%20until%3A2018-08-29.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-08-10%20until%3A2018-08-11.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-08-26%20until%3A2018-08-28.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-08-29%20until%3A2018-08-31.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-08-16%20until%3A2018-08-17.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-08-07%20until%3A2018-08-08.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-08-20%20until%3A2018-08-22.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-08-22%20until%3A2018-08-23.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-08-17%20until%3A2018-08-19.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-08-19%20until%3A2018-08-20.\n",
      "INFO: Got 0 tweets (0 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-01 2018-09-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: queries: ['skin since:2018-09-01 until:2018-09-02', 'skin since:2018-09-02 until:2018-09-03', 'skin since:2018-09-03 until:2018-09-05', 'skin since:2018-09-05 until:2018-09-06', 'skin since:2018-09-06 until:2018-09-08', 'skin since:2018-09-08 until:2018-09-09', 'skin since:2018-09-09 until:2018-09-11', 'skin since:2018-09-11 until:2018-09-12', 'skin since:2018-09-12 until:2018-09-14', 'skin since:2018-09-14 until:2018-09-15', 'skin since:2018-09-15 until:2018-09-16', 'skin since:2018-09-16 until:2018-09-18', 'skin since:2018-09-18 until:2018-09-19', 'skin since:2018-09-19 until:2018-09-21', 'skin since:2018-09-21 until:2018-09-22', 'skin since:2018-09-22 until:2018-09-24', 'skin since:2018-09-24 until:2018-09-25', 'skin since:2018-09-25 until:2018-09-27', 'skin since:2018-09-27 until:2018-09-28', 'skin since:2018-09-28 until:2018-09-30']\n",
      "INFO: Querying skin since:2018-09-02 until:2018-09-03\n",
      "INFO: Querying skin since:2018-09-01 until:2018-09-02\n",
      "INFO: Querying skin since:2018-09-03 until:2018-09-05\n",
      "INFO: Querying skin since:2018-09-11 until:2018-09-12\n",
      "INFO: Querying skin since:2018-09-05 until:2018-09-06\n",
      "INFO: Querying skin since:2018-09-06 until:2018-09-08\n",
      "INFO: Querying skin since:2018-09-12 until:2018-09-14\n",
      "INFO: Querying skin since:2018-09-14 until:2018-09-15\n",
      "INFO: Querying skin since:2018-09-09 until:2018-09-11\n",
      "INFO: Querying skin since:2018-09-08 until:2018-09-09\n",
      "INFO: Querying skin since:2018-09-15 until:2018-09-16\n",
      "INFO: Querying skin since:2018-09-16 until:2018-09-18\n",
      "INFO: Querying skin since:2018-09-18 until:2018-09-19\n",
      "INFO: Querying skin since:2018-09-19 until:2018-09-21\n",
      "INFO: Querying skin since:2018-09-21 until:2018-09-22\n",
      "INFO: Querying skin since:2018-09-22 until:2018-09-24\n",
      "INFO: Querying skin since:2018-09-24 until:2018-09-25\n",
      "INFO: Querying skin since:2018-09-28 until:2018-09-30\n",
      "INFO: Querying skin since:2018-09-25 until:2018-09-27\n",
      "INFO: Querying skin since:2018-09-27 until:2018-09-28\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-09-19%20until%3A2018-09-21.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-09-01%20until%3A2018-09-02.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-09-03%20until%3A2018-09-05.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-09-15%20until%3A2018-09-16.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-09-28%20until%3A2018-09-30.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-09-16%20until%3A2018-09-18.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-09-12%20until%3A2018-09-14.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-09-27%20until%3A2018-09-28.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-09-22%20until%3A2018-09-24.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-09-25%20until%3A2018-09-27.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-09-14%20until%3A2018-09-15.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-09-09%20until%3A2018-09-11.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-09-11%20until%3A2018-09-12.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-09-24%20until%3A2018-09-25.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-09-18%20until%3A2018-09-19.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-09-06%20until%3A2018-09-08.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-09-21%20until%3A2018-09-22.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-09-08%20until%3A2018-09-09.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-09-02%20until%3A2018-09-03.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-09-05%20until%3A2018-09-06.\n",
      "INFO: Got 0 tweets (0 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-01 2018-10-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: queries: ['skin since:2018-10-01 until:2018-10-02', 'skin since:2018-10-02 until:2018-10-04', 'skin since:2018-10-04 until:2018-10-05', 'skin since:2018-10-05 until:2018-10-07', 'skin since:2018-10-07 until:2018-10-08', 'skin since:2018-10-08 until:2018-10-10', 'skin since:2018-10-10 until:2018-10-11', 'skin since:2018-10-11 until:2018-10-13', 'skin since:2018-10-13 until:2018-10-14', 'skin since:2018-10-14 until:2018-10-16', 'skin since:2018-10-16 until:2018-10-17', 'skin since:2018-10-17 until:2018-10-19', 'skin since:2018-10-19 until:2018-10-20', 'skin since:2018-10-20 until:2018-10-22', 'skin since:2018-10-22 until:2018-10-23', 'skin since:2018-10-23 until:2018-10-25', 'skin since:2018-10-25 until:2018-10-26', 'skin since:2018-10-26 until:2018-10-28', 'skin since:2018-10-28 until:2018-10-29', 'skin since:2018-10-29 until:2018-10-31']\n",
      "INFO: Querying skin since:2018-10-01 until:2018-10-02\n",
      "INFO: Querying skin since:2018-10-02 until:2018-10-04\n",
      "INFO: Querying skin since:2018-10-04 until:2018-10-05\n",
      "INFO: Querying skin since:2018-10-05 until:2018-10-07\n",
      "INFO: Querying skin since:2018-10-08 until:2018-10-10\n",
      "INFO: Querying skin since:2018-10-07 until:2018-10-08\n",
      "INFO: Querying skin since:2018-10-11 until:2018-10-13\n",
      "INFO: Querying skin since:2018-10-10 until:2018-10-11\n",
      "INFO: Querying skin since:2018-10-14 until:2018-10-16\n",
      "INFO: Querying skin since:2018-10-16 until:2018-10-17\n",
      "INFO: Querying skin since:2018-10-13 until:2018-10-14\n",
      "INFO: Querying skin since:2018-10-17 until:2018-10-19\n",
      "INFO: Querying skin since:2018-10-19 until:2018-10-20\n",
      "INFO: Querying skin since:2018-10-22 until:2018-10-23\n",
      "INFO: Querying skin since:2018-10-20 until:2018-10-22\n",
      "INFO: Querying skin since:2018-10-23 until:2018-10-25\n",
      "INFO: Querying skin since:2018-10-26 until:2018-10-28\n",
      "INFO: Querying skin since:2018-10-25 until:2018-10-26\n",
      "INFO: Querying skin since:2018-10-28 until:2018-10-29\n",
      "INFO: Querying skin since:2018-10-29 until:2018-10-31\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-10-28%20until%3A2018-10-29.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-10-20%20until%3A2018-10-22.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-10-07%20until%3A2018-10-08.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-10-10%20until%3A2018-10-11.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-10-25%20until%3A2018-10-26.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-10-11%20until%3A2018-10-13.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-10-17%20until%3A2018-10-19.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-10-23%20until%3A2018-10-25.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-10-26%20until%3A2018-10-28.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-10-22%20until%3A2018-10-23.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-10-01%20until%3A2018-10-02.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-10-13%20until%3A2018-10-14.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-10-05%20until%3A2018-10-07.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-10-02%20until%3A2018-10-04.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-10-19%20until%3A2018-10-20.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-10-04%20until%3A2018-10-05.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-10-29%20until%3A2018-10-31.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-10-08%20until%3A2018-10-10.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-10-14%20until%3A2018-10-16.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-10-16%20until%3A2018-10-17.\n",
      "INFO: Got 0 tweets (0 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-01 2018-11-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: queries: ['skin since:2018-11-01 until:2018-11-02', 'skin since:2018-11-02 until:2018-11-03', 'skin since:2018-11-03 until:2018-11-05', 'skin since:2018-11-05 until:2018-11-06', 'skin since:2018-11-06 until:2018-11-08', 'skin since:2018-11-08 until:2018-11-09', 'skin since:2018-11-09 until:2018-11-11', 'skin since:2018-11-11 until:2018-11-12', 'skin since:2018-11-12 until:2018-11-14', 'skin since:2018-11-14 until:2018-11-15', 'skin since:2018-11-15 until:2018-11-16', 'skin since:2018-11-16 until:2018-11-18', 'skin since:2018-11-18 until:2018-11-19', 'skin since:2018-11-19 until:2018-11-21', 'skin since:2018-11-21 until:2018-11-22', 'skin since:2018-11-22 until:2018-11-24', 'skin since:2018-11-24 until:2018-11-25', 'skin since:2018-11-25 until:2018-11-27', 'skin since:2018-11-27 until:2018-11-28', 'skin since:2018-11-28 until:2018-11-30']\n",
      "INFO: Querying skin since:2018-11-01 until:2018-11-02\n",
      "INFO: Querying skin since:2018-11-02 until:2018-11-03\n",
      "INFO: Querying skin since:2018-11-05 until:2018-11-06\n",
      "INFO: Querying skin since:2018-11-06 until:2018-11-08\n",
      "INFO: Querying skin since:2018-11-11 until:2018-11-12\n",
      "INFO: Querying skin since:2018-11-09 until:2018-11-11\n",
      "INFO: Querying skin since:2018-11-08 until:2018-11-09\n",
      "INFO: Querying skin since:2018-11-03 until:2018-11-05\n",
      "INFO: Querying skin since:2018-11-12 until:2018-11-14\n",
      "INFO: Querying skin since:2018-11-15 until:2018-11-16\n",
      "INFO: Querying skin since:2018-11-14 until:2018-11-15\n",
      "INFO: Querying skin since:2018-11-22 until:2018-11-24\n",
      "INFO: Querying skin since:2018-11-21 until:2018-11-22\n",
      "INFO: Querying skin since:2018-11-19 until:2018-11-21\n",
      "INFO: Querying skin since:2018-11-25 until:2018-11-27\n",
      "INFO: Querying skin since:2018-11-24 until:2018-11-25\n",
      "INFO: Querying skin since:2018-11-27 until:2018-11-28\n",
      "INFO: Querying skin since:2018-11-28 until:2018-11-30\n",
      "INFO: Querying skin since:2018-11-16 until:2018-11-18\n",
      "INFO: Querying skin since:2018-11-18 until:2018-11-19\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-11-09%20until%3A2018-11-11.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-11-01%20until%3A2018-11-02.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-11-08%20until%3A2018-11-09.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-11-05%20until%3A2018-11-06.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-11-02%20until%3A2018-11-03.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-11-11%20until%3A2018-11-12.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-11-19%20until%3A2018-11-21.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-11-21%20until%3A2018-11-22.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-11-24%20until%3A2018-11-25.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-11-28%20until%3A2018-11-30.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-11-12%20until%3A2018-11-14.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-11-18%20until%3A2018-11-19.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-11-14%20until%3A2018-11-15.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-11-25%20until%3A2018-11-27.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-11-16%20until%3A2018-11-18.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-11-03%20until%3A2018-11-05.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-11-15%20until%3A2018-11-16.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-11-22%20until%3A2018-11-24.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-11-06%20until%3A2018-11-08.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-11-27%20until%3A2018-11-28.\n",
      "INFO: Got 0 tweets (0 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-01 2018-12-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: queries: ['skin since:2018-12-01 until:2018-12-02', 'skin since:2018-12-02 until:2018-12-04', 'skin since:2018-12-04 until:2018-12-05', 'skin since:2018-12-05 until:2018-12-07', 'skin since:2018-12-07 until:2018-12-08', 'skin since:2018-12-08 until:2018-12-10', 'skin since:2018-12-10 until:2018-12-11', 'skin since:2018-12-11 until:2018-12-13', 'skin since:2018-12-13 until:2018-12-14', 'skin since:2018-12-14 until:2018-12-16', 'skin since:2018-12-16 until:2018-12-17', 'skin since:2018-12-17 until:2018-12-19', 'skin since:2018-12-19 until:2018-12-20', 'skin since:2018-12-20 until:2018-12-22', 'skin since:2018-12-22 until:2018-12-23', 'skin since:2018-12-23 until:2018-12-25', 'skin since:2018-12-25 until:2018-12-26', 'skin since:2018-12-26 until:2018-12-28', 'skin since:2018-12-28 until:2018-12-29', 'skin since:2018-12-29 until:2018-12-31']\n",
      "INFO: Querying skin since:2018-12-01 until:2018-12-02\n",
      "INFO: Querying skin since:2018-12-04 until:2018-12-05\n",
      "INFO: Querying skin since:2018-12-07 until:2018-12-08\n",
      "INFO: Querying skin since:2018-12-05 until:2018-12-07\n",
      "INFO: Querying skin since:2018-12-02 until:2018-12-04\n",
      "INFO: Querying skin since:2018-12-10 until:2018-12-11\n",
      "INFO: Querying skin since:2018-12-08 until:2018-12-10\n",
      "INFO: Querying skin since:2018-12-13 until:2018-12-14\n",
      "INFO: Querying skin since:2018-12-11 until:2018-12-13\n",
      "INFO: Querying skin since:2018-12-14 until:2018-12-16\n",
      "INFO: Querying skin since:2018-12-17 until:2018-12-19\n",
      "INFO: Querying skin since:2018-12-16 until:2018-12-17\n",
      "INFO: Querying skin since:2018-12-19 until:2018-12-20\n",
      "INFO: Querying skin since:2018-12-20 until:2018-12-22\n",
      "INFO: Querying skin since:2018-12-22 until:2018-12-23\n",
      "INFO: Querying skin since:2018-12-25 until:2018-12-26\n",
      "INFO: Querying skin since:2018-12-23 until:2018-12-25\n",
      "INFO: Querying skin since:2018-12-26 until:2018-12-28\n",
      "INFO: Querying skin since:2018-12-28 until:2018-12-29\n",
      "INFO: Querying skin since:2018-12-29 until:2018-12-31\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-12-29%20until%3A2018-12-31.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-12-08%20until%3A2018-12-10.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-12-25%20until%3A2018-12-26.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-12-13%20until%3A2018-12-14.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-12-10%20until%3A2018-12-11.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-12-05%20until%3A2018-12-07.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-12-26%20until%3A2018-12-28.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-12-22%20until%3A2018-12-23.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-12-07%20until%3A2018-12-08.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-12-16%20until%3A2018-12-17.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-12-28%20until%3A2018-12-29.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-12-20%20until%3A2018-12-22.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-12-14%20until%3A2018-12-16.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-12-01%20until%3A2018-12-02.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-12-17%20until%3A2018-12-19.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-12-23%20until%3A2018-12-25.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-12-04%20until%3A2018-12-05.\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-12-02%20until%3A2018-12-04.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-12-11%20until%3A2018-12-13.\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets (0 new).\n",
      "INFO: Got 0 tweets for skin%20since%3A2018-12-19%20until%3A2018-12-20.\n",
      "INFO: Got 0 tweets (0 new).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-01 2019-01-31\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3077\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3078\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'timestamp'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1bcf2a6d1c55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mtweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweety\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mtweets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mset_index\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   3907\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3908\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3909\u001b[0;31m                 \u001b[0mlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3910\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3911\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3078\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'timestamp'"
     ]
    }
   ],
   "source": [
    "# ENTER QUERY TERM AND DATES TO SEARCH - REPEAT MONTHLY\n",
    "query = \"skin\"\n",
    "begin = dt.date(2018,1,1)\n",
    "end = dt.date(2018,1,31)\n",
    "\n",
    "tweety = []\n",
    "\n",
    "for i in range(12):\n",
    "    tweety.extend(get_query(query, begin, end))\n",
    "    begin = end + timedelta(1)\n",
    "    \n",
    "    x = begin\n",
    "    d = 1\n",
    "    while x.month == begin.month:\n",
    "        x = begin + timedelta(d)\n",
    "        d+=1\n",
    "    end = x - timedelta(1)\n",
    "    print(begin, end)\n",
    "    \n",
    "\n",
    "tweets = pd.DataFrame(tweety)\n",
    "tweets.set_index('timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.DataFrame(tweety)\n",
    "tweets.set_index('timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "tweets.drop_duplicates(inplace=True)\n",
    "print(f\"Total: {tweets.shape[0]}\")\n",
    "print(f\"Unique: {tweets['id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append results to .csv file\n",
    "with open('./2018skin.csv', 'a') as f: \n",
    "    tweets.to_csv(f, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADDITIONAL DATA TO BE ADDED LATER(?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get home timeline tweets\n",
    "public_tweets = api.home_timeline()\n",
    "for tweet in public_tweets:\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the User object for twitter...\n",
    "user = api.get_user('twitter')\n",
    "print (user.screen_name)\n",
    "print (user.followers_count)\n",
    "for friend in user.friends():\n",
    "   print(friend.screen_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = api.get_user('diabeteshealth')\n",
    "print (user.screen_name)\n",
    "print (user.followers_count)\n",
    "for friend in user.friends():\n",
    "   print(friend.screen_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get timeline tweets from specific user\n",
    "tweetys = api.user_timeline('DiabetesHealth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object.html\n",
    "tweets_user_dict = {'created_at':[],\n",
    "              'id_str':[],\n",
    "              'text':[],\n",
    "              'user-screen_name':[],\n",
    "              'user-id_str':[],\n",
    "              'user-location':[],\n",
    "              'user-description':[],\n",
    "              'user-verified':[],\n",
    "              'user-followers_count':[],\n",
    "              'retweet_count':[],\n",
    "              'favorite_count':[]\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in tweets:\n",
    "    # Append info to tweets_dict\n",
    "    tweets_user_dict['created_at'].append(tweet.created_at)\n",
    "    tweets_user_dict['id_str'].append(tweet.id_str)\n",
    "    tweets_user_dict['text'].append(tweet.text)\n",
    "    tweets_user_dict['user-screen_name'].append(tweet.user.screen_name)\n",
    "    tweets_user_dict['user-id_str'].append(tweet.user.id_str)\n",
    "    tweets_user_dict['user-location'].append(tweet.user.location)\n",
    "    tweets_user_dict['user-description'].append(tweet.user.description)\n",
    "    tweets_user_dict['user-verified'].append(tweet.user.verified)\n",
    "    tweets_user_dict['user-followers_count'].append(tweet.user.followers_count)\n",
    "    tweets_user_dict['retweet_count'].append(tweet.retweet_count)\n",
    "    tweets_user_dict['favorite_count'].append(tweet.favorite_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save posts to dataframe\n",
    "tweets_df = pd.DataFrame(tweets_user_dict)\n",
    "tweets_df.set_index('created_at', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# api.get_user('desantisa').location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append results to scrapedtweets.csv\n",
    "with open('./scrapedtweets.csv', 'a') as f:\n",
    "    tweets.to_csv(f, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to return URL\n",
    "def get_url(timestamp):\n",
    "    user = tweets[timestamp]['user'][0]\n",
    "    tweet_id = tweets[timestamp]['id'][0]\n",
    "    print(f'https://twitter.com/{user}/status/{tweet_id}')\n",
    "    \n",
    "## Request URL by timestamp\n",
    "get_url('2018-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA CAMP CODE FOR COLLECTING ADDITIONAL INFO ON USERS / RETWEETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/SocialDataAnalytics-Winter2018/lab04/blob/master/slistener.py\n",
    "# FULL CODE TO USE STREAMLISTENER \n",
    "\n",
    "class SListener(StreamListener):\n",
    "    def __init__(self, api = None):\n",
    "        self.output  = open('tweets_%s.json' %\n",
    "            time.strftime('%Y%m%d-%H%M%S'), 'w')\n",
    "        self.api = api or API()\n",
    "        \n",
    "    def on_data(self, data):\n",
    "        if  'in_reply_to_status' in data:\n",
    "            self.on_status(data)\n",
    "        elif 'delete' in data:\n",
    "            delete = json.loads(data)['delete']['status']\n",
    "            if self.on_delete(delete['id'], delete['user_id']) is False:\n",
    "                return False\n",
    "        elif 'limit' in data:\n",
    "            if self.on_limit(json.loads(data)['limit']['track']) is False:\n",
    "                return False\n",
    "        elif 'warning' in data:\n",
    "            warning = json.loads(data)['warnings']\n",
    "            print(\"WARNING: %s\" % warning['message'])\n",
    "            return\n",
    "\n",
    "\n",
    "    def on_status(self, status):\n",
    "        self.output.write(status)\n",
    "        self.counter += 1\n",
    "        if self.counter >= 20000:\n",
    "            self.output.close()\n",
    "            self.output  = open('%s_%s.json' % (self.fprefix, time.strftime('%Y%m%d-%H%M%S')), 'w')\n",
    "            self.counter = 0\n",
    "        return\n",
    "\n",
    "\n",
    "    def on_delete(self, status_id, user_id):\n",
    "        print(\"Delete notice\")\n",
    "        return\n",
    "\n",
    "\n",
    "    def on_limit(self, track):\n",
    "        print(\"WARNING: Limitation notice received, tweets missed: %d\" % track)\n",
    "        return\n",
    "\n",
    "\n",
    "    def on_error(self, status_code):\n",
    "        print('Encountered error with status code:', status_code)\n",
    "        return \n",
    "\n",
    "\n",
    "    def on_timeout(self):\n",
    "        print(\"Timeout, sleeping for 60 seconds...\")\n",
    "        time.sleep(60)\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweepy import Stream\n",
    "\n",
    "# Set up words to track \n",
    "\n",
    "keywords_to_track = ['#diabetes', '#diabetic']\n",
    "\n",
    "# Instantiate the SListener object \n",
    "listen = SListener(api)\n",
    "\n",
    "# Instantiate the Stream object\n",
    "stream = Stream(auth, listen)\n",
    "\n",
    "# stream.sample()\n",
    "\n",
    "# Begin collecting data\n",
    "stream.filter(track = keywords_to_track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load JSON\n",
    "# import json\n",
    "\n",
    "\n",
    "# # Convert from JSON to Python object\n",
    "tweet = json.loads(tweet)\n",
    "\n",
    "# Print tweet text\n",
    "print(tweet['text'])\n",
    "\n",
    "# Print tweet id\n",
    "print(tweet['id'])\n",
    "\n",
    "# Print user handle\n",
    "print(tweet['user']['screen_name'])\n",
    "\n",
    "# Print user follower count\n",
    "print(tweet['user']['followers_count'])\n",
    "\n",
    "# Print user location\n",
    "print(tweet['user']['location'])\n",
    "\n",
    "# Print user description\n",
    "print(tweet['user']['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print the text of the tweet\n",
    "print(rt['text'])\n",
    "\n",
    "# Print the text of tweet which has been retweeted\n",
    "print(rt['retweeted_status']['text'])\n",
    "\n",
    "# Print the user handle of the tweet\n",
    "print(rt['user']['screen_name'])\n",
    "\n",
    "# Print the user handle of the tweet which has been retweeted\n",
    "print(rt['retweeted_status']['user']['screen_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROCESSING TWITTER TEXT  \n",
    "# Print the tweet text\n",
    "print(quoted_tweet['text'])\n",
    "\n",
    "# Print the quoted tweet text\n",
    "print(quoted_tweet['quoted_status']['text'])\n",
    "\n",
    "# Print the quoted tweet's extended (140+) text\n",
    "print(quoted_tweet['quoted_status']['extended_tweet']['full_text'])\n",
    "\n",
    "# Print the quoted user location\n",
    "print(quoted_tweet['quoted_status']['user']['location'])\n",
    "\n",
    "\n",
    "# Store the user screen_name in 'user-screen_name'\n",
    "quoted_tweet['user-screen_name'] = quoted_tweet['user']['screen_name']\n",
    "\n",
    "# Store the quoted_status text in 'quoted_status-text'\n",
    "quoted_tweet['quoted_status-text'] = quoted_tweet['quoted_status']['text']\n",
    "\n",
    "# Store the quoted tweet's extended (140+) text in \n",
    "# 'quoted_status-extended_tweet-full_text'\n",
    "quoted_tweet['quoted_status-extended_tweet-full_text'] = quoted_tweet['quoted_status']['extended_tweet']['full_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_tweets(tweets_json):\n",
    "    \"\"\" Flattens out tweet dictionaries so relevant JSON\n",
    "        is in a top-level dictionary.\"\"\"\n",
    "    tweets_list = []\n",
    "    \n",
    "    # Iterate through each tweet\n",
    "    for tweet in tweets_json:\n",
    "        tweet_obj = json.loads(tweet)\n",
    "    \n",
    "        # Store the user screen name in 'user-screen_name'\n",
    "        tweet_obj['user-screen_name'] = tweet_obj['user']['screen_name']\n",
    "    \n",
    "        # Check if this is a 140+ character tweet\n",
    "        if 'extended_tweet' in tweet_obj:\n",
    "            # Store the extended tweet text in 'extended_tweet-full_text'\n",
    "            tweet_obj['extended_tweet-full_text'] = tweet_obj['extended_tweet']['full_text']\n",
    "    \n",
    "        if 'retweeted_status' in tweet_obj:\n",
    "            # Store the retweet user screen name in 'retweeted_status-user-screen_name'\n",
    "            tweet_obj['retweeted_status-user-screen_name'] = tweet_obj['retweeted_status']['user']['screen_name']\n",
    "\n",
    "            # Store the retweet text in 'retweeted_status-text'\n",
    "            tweet_obj['retweeted_status-text'] = tweet_obj['retweeted_status']['text']\n",
    "            \n",
    "        tweets_list.append(tweet_obj)\n",
    "    return tweets_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Flatten the tweets and store in `tweets`\n",
    "tweets = flatten_tweets(data_science_json)\n",
    "\n",
    "# Create a DataFrame from `tweets`\n",
    "ds_tweets = pd.DataFrame(tweets)\n",
    "\n",
    "# Print out the first 5 tweets from this dataset\n",
    "print(ds_tweets['text'].values[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Flatten the tweets and store them\n",
    "flat_tweets = flatten_tweets(data_science_json)\n",
    "\n",
    "# Convert to DataFrame\n",
    "ds_tweets = pd.DataFrame(flat_tweets)\n",
    "\n",
    "# Find mentions of #diabetes in 'text'\n",
    "diabetes = ds_tweets['text'].str.contains('#diabetes', case = False)\n",
    "\n",
    "# Print proportion of tweets mentioning #diabetes\n",
    "print(\"Proportion of #diabetes tweets:\", np.sum(diabetes) / ds_tweets.shape[0])\n",
    "\n",
    "\n",
    "def check_word_in_tweet(word, data):\n",
    "    \"\"\"Checks if a word is in a Twitter dataset's text. \n",
    "    Checks text and extended tweet (140+ character tweets) for tweets,\n",
    "    retweets and quoted tweets.\n",
    "    Returns a logical pandas Series.\n",
    "    \"\"\"\n",
    "    contains_column = data['text'].str.contains(word, case = False)\n",
    "    contains_column |= data['extended_tweet-full_text'].str.contains(word, case = False)\n",
    "    contains_column |= data['quoted_status-text'].str.contains(word, case = False)\n",
    "    contains_column |= data['quoted_status-extended_tweet-full_text'].str.contains(word, case = False)\n",
    "    contains_column |= data['retweeted_status-extended_tweet-full_text'].str.contains(word, case = False)\n",
    "    contains_column |= data['retweeted_status-text'].str.contains(word, case = False)\n",
    "    return contains_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find mentions of #diabetes in all text fields\n",
    "diabetes = check_word_in_tweet('#diabetes', ds_tweets)\n",
    "\n",
    "# Find mentions of #rstats in all text fields\n",
    "diabetic = check_word_in_tweet('#diabetic', ds_tweets)\n",
    "\n",
    "# Print proportion of tweets mentioning #diabetes\n",
    "print(\"Proportion of #diabetes tweets:\", np.sum(diabetes) / ds_tweets.shape[0])\n",
    "\n",
    "# Print proportion of tweets mentioning #diabetic\n",
    "print(\"Proportion of #diabetic tweets:\", np.sum(diabetic) / ds_tweets.shape[0])\n",
    "\n",
    "\n",
    "# Print created_at to see the original format of datetime in Twitter data\n",
    "print(ds_tweets['created_at'].head()) \n",
    "\n",
    "# Convert the created_at column to np.datetime object\n",
    "ds_tweets['created_at'] = pd.to_datetime(ds_tweets['created_at'])\n",
    "\n",
    "# Print created_at to see new format\n",
    "print(ds_tweets['created_at'].head())\n",
    "  \n",
    "# Set the index of ds_tweets to created_at\n",
    "ds_tweets = ds_tweets.set_index('created_at')\n",
    "\n",
    "\n",
    "\n",
    "# Create a diabetes column\n",
    "ds_tweets['diabetes'] = check_word_in_tweet('#diabetes', ds_tweets)\n",
    "\n",
    "# Create a diabetic column\n",
    "ds_tweets['diabetic'] = check_word_in_tweet('#diabetic', ds_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average of  diabetes column by day\n",
    "mean_diabetes = ds_tweets['diabetes'].resample('1 d').mean()\n",
    "\n",
    "# Average of diabetic column by day\n",
    "mean_diabetic = ds_tweets['diabetic'].resample('1 d').mean()\n",
    "\n",
    "# Plot mean diabetes by day(green)/mean rstats by day(blue)\n",
    "plt.plot(mean_diabetes.index.day, mean_diabetes, color = 'green')\n",
    "plt.plot(mean_diabetic.index.day, mean_diabetic, color = 'blue')\n",
    "\n",
    "# Add labels and show\n",
    "plt.xlabel('Day'); plt.ylabel('Frequency')\n",
    "plt.title('Language mentions over time')\n",
    "plt.legend(('#diabetes', '#diabetic'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SentimentIntensityAnalyzer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Instantiate new SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Generate sentiment scores\n",
    "sentiment_scores = ds_tweets['text'].apply(sid.polarity_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the text of a positive tweet\n",
    "print(ds_tweets[sentiment > 0.6]['text'].values[0])\n",
    "\n",
    "# Print out the text of a negative tweet\n",
    "print(ds_tweets[sentiment < -0.6]['text'].values[0])\n",
    "\n",
    "# Generate average sentiment scores for #diabetes\n",
    "sentiment_diabetes = sentiment[ check_word_in_tweet('#diabetes', ds_tweets) ].resample('1 d').mean()\n",
    "\n",
    "# Generate average sentiment scores for #rstats\n",
    "sentiment_diabetic = sentiment[ check_word_in_tweet('#diabetic', ds_tweets) ].resample('1 d').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot average #diabetes sentiment per day\n",
    "plt.plot(sentiment_diabetes.index.day, sentiment_diabetes, color = 'green')\n",
    "\n",
    "# Plot average #rstats sentiment per day\n",
    "plt.plot(sentiment_diabetic.index.day, sentiment_diabetic, color = 'blue')\n",
    "\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Sentiment')\n",
    "plt.title('Sentiment of data science languages')\n",
    "plt.legend(('#diabetes', '#diabetic'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NETWORK ANALYSIS \n",
    "\n",
    "# Import networkx\n",
    "import networkx as nx\n",
    " \n",
    "\n",
    "# Create reply network from edgelist\n",
    "G_reply = nx.from_pandas_edgelist(\n",
    "    sotu_replies,\n",
    "    source = 'user-screen_name', \n",
    "    target = 'in_reply_to_screen_name',\n",
    "    create_using = nx.DiGraph())\n",
    " \n",
    "\n",
    "# Print the number of nodes\n",
    "print('Nodes in reply network:', len(G_reply.nodes()))\n",
    "\n",
    "# Print the number of edges\n",
    "print('Edges in reply network:', len(G_reply.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization\n",
    "# Create random layout positions\n",
    "pos = nx.random_layout(G_rt)\n",
    "\n",
    "# Create size list\n",
    "sizes = [x[1] for x in G_rt.degree()]\n",
    "\n",
    "# Draw the network\n",
    "nx.draw_networkx(G_rt, pos, \n",
    "    with_labels = False, \n",
    "    node_size = sizes,\n",
    "    width = 0.1, alpha = 0.7,\n",
    "    arrowsize = 2, linewidths = 0)\n",
    "\n",
    "# Turn axis off and show\n",
    "plt.axis('off'); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#networkx has been imported as nx. Also, the networks G_rt and G_reply and column_names = ['screen_name', 'degree_centrality']\n",
    "# Generate in-degree centrality for retweets \n",
    "rt_centrality = nx.in_degree_centrality(G_rt)\n",
    "\n",
    "# Generate in-degree centrality for replies \n",
    "reply_centrality = nx.in_degree_centrality(G_reply)\n",
    "\n",
    "# Store centralities in DataFrame\n",
    "rt = pd.DataFrame(list(rt_centrality.items()), columns = column_names)\n",
    "reply = pd.DataFrame(list(reply_centrality.items()), columns = column_names)\n",
    "\n",
    "# Print first five results in descending order of centrality\n",
    "print(rt.sort_values('degree_centrality', ascending = False).head())\n",
    "\n",
    "# Print first five results in descending order of centrality\n",
    "print(reply.sort_values('degree_centrality', ascending = False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#networkx has been imported as nx. The networks G_rt and G_reply, and column_names = ['screen_name', 'betweenness_centrality']\n",
    "\n",
    "# Generate betweenness centrality for retweets \n",
    "rt_centrality = nx.betweenness_centrality(G_rt)\n",
    "\n",
    "# Generate betweenness centrality for replies \n",
    "reply_centrality = nx.betweenness_centrality(G_reply)\n",
    "\n",
    "# Store centralities in data frames \n",
    " \n",
    "rt = pd.DataFrame(list(rt_centrality.items()), columns = column_names)\n",
    "\n",
    "reply = pd.DataFrame(list(reply_centrality.items()), columns = column_names)\n",
    "\n",
    "\n",
    "# Print first five results in descending order of centrality\n",
    "print(rt.sort_values('betweenness_centrality', ascending = False).head())\n",
    "\n",
    "# Print first five results in descending order of centrality\n",
    "print(reply.sort_values('betweenness_centrality', ascending = False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The networks G_rt and G_reply, and column_names = ['screen_name', 'degree']have been \n",
    "# loaded for you.\n",
    "\n",
    "# Calculate in-degrees and store in DataFrame\n",
    "degree_rt = pd.DataFrame(list(G_rt.in_degree()), columns = column_names)\n",
    "degree_reply = pd.DataFrame(list(G_reply.in_degree()), columns = column_names)\n",
    "\n",
    "# Merge the two DataFrames on screen name\n",
    "ratio = degree_rt.merge(degree_reply, on = 'screen_name', suffixes = ('_rt', '_reply'))\n",
    "\n",
    "# Calculate the ratio\n",
    "ratio['ratio'] = ratio['degree_reply'] / ratio['degree_rt']\n",
    "\n",
    "# Exclude any tweets with less than 5 retweets\n",
    "ratio = ratio[ratio['degree_rt'] >= 5]\n",
    "\n",
    "# Print out first five with highest ratio\n",
    "print(ratio.sort_values('ratio', ascending = False).head())\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAPPING TWITTER\n",
    "\n",
    "# Print out the location of a single tweet\n",
    "print(tweet_json['user']['location'])\n",
    "\n",
    "# Flatten and load the SOTU tweets into a dataframe \n",
    "tweets_sotu = pd.DataFrame(flatten_tweets(tweets_sotu_json))\n",
    "\n",
    "# Print out top five user-defined locations \n",
    "print(tweets_sotu['user-location'].value_counts().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBoundingBox(place):\n",
    "    \"\"\" Returns the bounding box coordinates.\"\"\"\n",
    "    return place['bounding_box']['coordinates'] \n",
    "\n",
    "# Apply the function which gets bounding box coordinates\n",
    "bounding_boxes = tweets_sotu['place'].apply(getBoundingBox)\n",
    "\n",
    "# Print out the first bounding box coordinates\n",
    "print(bounding_boxes.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateCentroid(place):\n",
    "    \"\"\" Calculates the centroid from a bounding box.\"\"\"\n",
    "    # Obtain the coordinates from the bounding box.\n",
    "    coordinates = place['bounding_box']['coordinates'][0]\n",
    "        \n",
    "    longs = np.unique( [x[0] for x in coordinates] )\n",
    "    lats  = np.unique( [x[1] for x in coordinates] )\n",
    "\n",
    "    if len(longs) == 1 and len(lats) == 1:\n",
    "        # return a single coordinate\n",
    "        return (longs[0], lats[0])\n",
    "    elif len(longs) == 2 and len(lats) == 2:\n",
    "        # If we have two longs and lats, we have a box.\n",
    "        central_long = np.sum(longs) / 2\n",
    "        central_lat  = np.sum(lats)/ 2\n",
    "    else:\n",
    "        raise ValueError(\"Non-rectangular polygon not supported: %s\" % \n",
    "            \",\".join(map(lambda x: str(x), coordinates)) )\n",
    "\n",
    "    return (central_long, central_lat)\n",
    "    \n",
    "# Calculate the centroids of place     \n",
    "centroids = tweets_sotu['place'].apply(calculateCentroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Basemap\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up the US bounding box\n",
    "us_boundingbox = [-125, 22, -64, 50] \n",
    "\n",
    "# Set up the Basemap object\n",
    "m = Basemap(llcrnrlon = us_boundingbox[0],\n",
    "            llcrnrlat = us_boundingbox[1],\n",
    "            urcrnrlon = us_boundingbox[2],\n",
    "            urcrnrlat = us_boundingbox[3],\n",
    "            projection='merc')\n",
    "\n",
    "# Draw continents in white,\n",
    "# coastlines and countries in gray\n",
    "m.fillcontinents(color='white')\n",
    "m.drawcoastlines(color='gray')\n",
    "m.drawcountries(color='gray')\n",
    "\n",
    "# Draw the states and show the plot\n",
    "m.drawstates(color='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the centroids for the dataset\n",
    "# and isolate longitudue and latitudes\n",
    "centroids = tweets_sotu['place'].apply(calculateCentroid)\n",
    "\n",
    "lon = [x[0] for x in centroids]\n",
    "lat = [x[1] for x in centroids]\n",
    "\n",
    "# Draw continents, coastlines, countries, and states\n",
    "m.fillcontinents(color='white', zorder = 0)\n",
    "m.drawcoastlines(color='gray')\n",
    "m.drawcountries(color='gray')\n",
    "m.drawstates(color='gray')\n",
    "\n",
    "# Draw the points and show the plot\n",
    "m.scatter(lat, lon, latlon = True, alpha = 0.7)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sentiment scores\n",
    "sentiment_scores = tweets_sotu[text].apply(sid.polarity_scores)\n",
    "\n",
    "# Isolate the compound element\n",
    "sentiment_scores = [x['compound'] for x in sentiment_scores]\n",
    "\n",
    "# Draw the points\n",
    "m.scatter(lat, lon, latlon = True, \n",
    "           c = sentiment_scores,\n",
    "           cmap = 'coolwarm', alpha = 0.7)\n",
    "           \n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
